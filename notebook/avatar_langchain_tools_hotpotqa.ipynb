{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "# test dataset used by retroformer and expel\n",
    "hotpot_test = joblib.load('hotpot-qa-distractor-sample.joblib').reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Example({'question': 'At My Window was released by which American singer-songwriter?', 'answer': 'John Townes Van Zandt'}) (input_keys={'question'}),\n",
       " Example({'question': \"VIVA Media AG changed it's name in 2004. What does their new acronym stand for?\", 'answer': 'Gesellschaft mit beschränkter Haftung'}) (input_keys={'paper_id', 'question'}))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dspy\n",
    "import os\n",
    "from dspy.evaluate import Evaluate\n",
    "from dspy.datasets.hotpotqa import HotPotQA\n",
    "from dspy.teleprompt import BootstrapFewShotWithRandomSearch\n",
    "\n",
    "# colbert = dspy.ColBERTv2(url='http://20.102.90.50:2017/wiki17_abstracts')\n",
    "\n",
    "dspy.settings.configure(\n",
    "    lm=dspy.OpenAI(\n",
    "        model=\"gpt-4o\", # \"gpt-4o\"\n",
    "        api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "        max_tokens=2048,\n",
    "        temperature=0\n",
    "    )\n",
    ")\n",
    "\n",
    "dataset = HotPotQA(train_seed=1, train_size=100, dev_size=0, test_size=0)\n",
    "trainset = [x.with_inputs('question') for x in dataset.train]\n",
    "test_set = [\n",
    "    dspy.Example(question=hotpot_test.iloc[i]['question'], answer=hotpot_test.iloc[i]['answer']).with_inputs(\"question\", \"paper_id\")\n",
    "    for i in range(len(hotpot_test))\n",
    "]\n",
    "\n",
    "# show an example datapoint; it's just a question-answer pair\n",
    "trainset[0], test_set[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReAct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.tools import Tool\n",
    "# from dspy.predict.parameter import Parameter\n",
    "# from langchain_community.utilities import GoogleSerperAPIWrapper, ArxivAPIWrapper, WikipediaAPIWrapper\n",
    "\n",
    "\n",
    "# class WebSearch(Parameter):\n",
    "#     name = \"WEB_SEARCH\"\n",
    "#     input_variable = \"query\"\n",
    "#     desc = \"If you have a question, you can use this tool to search the web for the answer.\"\n",
    "\n",
    "#     def forward(\n",
    "#         self,\n",
    "#         query_or_queries):\n",
    "#         return GoogleSerperAPIWrapper().run(query_or_queries)\n",
    "\n",
    "# # set attribute input_variable to google_tool\n",
    "# agent = dspy.ReAct(\"question -> answer\", tools=[dspy.Retrieve(k=3), WebSearch()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = dict(num_threads=8, display_progress=True, display_table=5)\n",
    "# evaluate = Evaluate(test_set=test_set, metric=dspy.evaluate.answer_exact_match, **config)\n",
    "\n",
    "# evaluate(agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AvaTaR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HotPotQASignature(dspy.Signature):\n",
    "    \"\"\"You will be given a question. Your task is to answer the question.\"\"\"\n",
    "    \n",
    "    question: str = dspy.InputField(\n",
    "        prefix=\"[[Question]]: \",\n",
    "        desc=\"question to ask\",\n",
    "        format=lambda x: x.strip(),\n",
    "    )\n",
    "    rationale: str = dspy.OutputField(\n",
    "        prefix=\"[[Rationale]]: \",\n",
    "        desc=\"Explanation or supporting evidence for the answer\",\n",
    "    )\n",
    "    answer: str = dspy.OutputField(\n",
    "        prefix=\"[[Answer]]: \",\n",
    "        desc=\"A short and direct answer (less than 10 words) to the question\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.predict.avatar import Tool, Avatar\n",
    "from langchain_community.utilities import GoogleSerperAPIWrapper, ArxivAPIWrapper, WikipediaAPIWrapper\n",
    "from langchain.tools import BaseTool, StructuredTool, tool\n",
    "from langchain_community.tools import WikipediaQueryRun\n",
    "\n",
    "\n",
    "def retrieve_from_wiki(query: str) -> str:\n",
    "    \"\"\"If you have a question or name to lookup, this tool uses wikipedia search for the answer.\"\"\"\n",
    "    return WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper()).run(query)\n",
    "\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        tool=StructuredTool.from_function(retrieve_from_wiki),\n",
    "        name=\"Wiki_SEARCH\",\n",
    "        desc=\"If you have a question or name to lookup, this tool uses wikipedia search for the answer.\"\n",
    "    ),\n",
    "    Tool(\n",
    "        tool=GoogleSerperAPIWrapper(),\n",
    "        name=\"WEB_SEARCH\",\n",
    "        desc=\"If you have a question, this tool uses google search for the answer.\"\n",
    "    )\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\t*** Since DSPy 2.5.16+, TypedPredictors are now deprecated, underperform, and are about to be removed! ***\n",
      "Please use standard predictors, e.g. dspy.Predict and dspy.ChainOfThought.\n",
      "They now support type annotations and other features of TypedPredictors and tend to work much better out of the box.\n",
      "Please let us know if you face any issues: https://github.com/stanfordnlp/dspy/issues\n"
     ]
    }
   ],
   "source": [
    "avatar_agent = Avatar(\n",
    "    tools=tools,\n",
    "    signature=HotPotQASignature,\n",
    "    verbose=False,\n",
    "    max_iters=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Open enden QA tasks are hard to evaluate on rigid metrics like exact match. So, we'll be using an improvised LLM as Judge for the evaluation of our model on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, string\n",
    "\n",
    "class Evaluator(dspy.Signature):\n",
    "    \"\"\"Please act as an impartial judge to evaluate whether the answer is correct based on the ground truth answer\"\"\"\n",
    "    \n",
    "    question: str = dspy.InputField(\n",
    "        prefix=\"Question:\",\n",
    "        desc=\"question to ask\",\n",
    "    )\n",
    "    reference_answer: str = dspy.InputField(\n",
    "        prefix=\"Ground truth answer:\",\n",
    "        desc=\"Ground truth answer to the question.\",\n",
    "    )\n",
    "    answer: str = dspy.InputField(\n",
    "        prefix=\"Answer:\",\n",
    "        desc=\"Answer to the question given by the model.\",\n",
    "    )\n",
    "    rationale: str = dspy.OutputField(\n",
    "        prefix=\"Rationale:\",\n",
    "        desc=\"Explanation of why the model's answer is correct or incorrect according to the ground truth answer.\",\n",
    "    )\n",
    "\n",
    "evaluator = dspy.TypedPredictor(Evaluator)\n",
    "def normalize_answer(s):\n",
    "    def remove_articles(text):\n",
    "        return re.sub(r\"\\b(a|an|the)\\b\", \" \", text)\n",
    "    \n",
    "    def white_space_fix(text):\n",
    "        return \" \".join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return \"\".join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "def EM(answer, key) -> bool:\n",
    "    return normalize_answer(answer) == normalize_answer(key)\n",
    "\n",
    "def metric(example, prediction, trace=None):\n",
    "    result = EM(prediction.answer.lower().strip(), example.answer.lower().strip())\n",
    "    print(prediction.answer.lower().strip(), '|', example.answer.lower().strip(), '=> ', result)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For evaluation we can't use `dspy.Evaluate`, reason being that `Avatar` changes it's signature per iteration by adding the actions and it's results to it as fields. So we can create our own hacky thread safe evaluator for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"False\"\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def process_example(example, signature):\n",
    "    try:\n",
    "        avatar = Avatar(\n",
    "            signature,\n",
    "            tools=tools,\n",
    "            verbose=False,\n",
    "            max_iters=10\n",
    "        )\n",
    "        prediction = avatar(**example.inputs().toDict())\n",
    "\n",
    "        return metric(example, prediction)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return 0\n",
    "\n",
    "# process_example(tool_qa[0], ToolQASignature)\n",
    "def multi_thread_executor(test_set, signature, num_threads=100):\n",
    "    total_score = 0\n",
    "    total_examples = len(test_set)\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "        futures = [executor.submit(process_example, example, signature) for example in test_set]\n",
    "\n",
    "        for future in tqdm.tqdm(futures, total=total_examples, desc=\"Processing examples\"):\n",
    "            total_score += future.result()\n",
    "\n",
    "    avg_metric = total_score / total_examples\n",
    "    return avg_metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\t*** In DSPy 2.5, all LM clients except `dspy.LM` are deprecated, underperform, and are about to be deleted. ***\n",
      " \t\tYou are using the client GPT3, which will be removed in DSPy 2.6.\n",
      " \t\tChanging the client is straightforward and will let you use new features (Adapters) that improve the consistency of LM outputs, especially when using chat LMs. \n",
      "\n",
      " \t\tLearn more about the changes and how to migrate at\n",
      " \t\thttps://github.com/stanfordnlp/dspy/blob/main/examples/migration.ipynb\n",
      "WARNING:root:\t*** In DSPy 2.5, all LM clients except `dspy.LM` are deprecated, underperform, and are about to be deleted. ***\n",
      " \t\tYou are using the client GPT3, which will be removed in DSPy 2.6.\n",
      " \t\tChanging the client is straightforward and will let you use new features (Adapters) that improve the consistency of LM outputs, especially when using chat LMs. \n",
      "\n",
      " \t\tLearn more about the changes and how to migrate at\n",
      " \t\thttps://github.com/stanfordnlp/dspy/blob/main/examples/migration.ipynb\n",
      "Processing examples:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alexander mcnair was from missouri. | bath, maine =>  False\n",
      "stedelijk museum | stedelijk museum amsterdam =>  False\n",
      "aloe vera of america | aloe vera of america =>  True\n",
      "california | california =>  True\n",
      "read it and weep | \"read it and weep\" (2006) =>  False\n",
      "enigma with the song \"amen\". | enigma =>  False\n",
      "\"shukratara mand vara\", \"shapat tula aahe\" | shukratara =>  False\n",
      "lester | lester =>  True\n",
      "minnesota | minnesota =>  True\n",
      "german culture | german =>  False\n",
      "2016 cannes film festival | 69th cannes film festival =>  False\n",
      "sarah kerrigan | sarah kerrigan =>  True\n",
      "creature comforts | creature comforts =>  True\n",
      "baltimore, maryland, u.s. | the port of baltimore west to sandy hook =>  False\n",
      "bhaktivedanta manor. | in the village of aldenham =>  False\n",
      "engineering | engineering =>  True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing examples:   1%|          | 1/100 [00:17<28:27, 17.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "albany | new york =>  False\n",
      "1978 | 1978 =>  True\n",
      "oklahoma sooners | oklahoma sooners =>  True\n",
      "1946 | 1927 =>  False\n",
      "gmbh | gesellschaft mit beschränkter haftung =>  False\n",
      "teen titans go! | teen titans go! =>  True\n",
      "duck dance | the twist =>  False\n",
      "m. night shyamalan | m. night shyamalan =>  True\n",
      "savannah, georgia is not in europe. | lacoste, france =>  False\n",
      "allegiant stadium | sam boyd stadium =>  False\n",
      "the dark tower series by stephen king | the dark tower =>  False\n",
      "2004 | 2004 =>  True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing examples:   3%|▎         | 3/100 [00:18<06:47,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marktown | marktown =>  True\n",
      "jonny craig | jonny\" craig =>  True\n",
      "anne perry | anne perry =>  True\n",
      "shakespeare's works include 39 plays, 154 sonnets, and poems. | chronological collection of critical quotations =>  False\n",
      "captain hans geering | captain hans geering =>  True\n",
      "sir patrick vallance | frederick alexander =>  False\n",
      "bluegrass airport | blue grass airport =>  False\n",
      "oneida limited | oneida limited =>  True\n",
      "cannot determine without specific information on rock nominees ltd. | cleaning, catering and security =>  False\n",
      "2 march 1972 | 2 march 1972 =>  True\n",
      "loughborough university | loughborough university =>  True\n",
      "\"you're next\" was filmed first. | you're next =>  False\n",
      "discovery zone | discovery zone =>  True\n",
      "2011 pulitzer prize in nonfiction. | pulitzer prize =>  False\n",
      "adam levine | adam levine =>  True\n",
      "juliet capulet | tybalt =>  False\n",
      "the battle of white plains | new york and new jersey campaign =>  False\n",
      "papa gino's | papa gino's =>  True\n",
      "ricky rubio | ricard rubio i vives =>  False\n",
      "opry mills is a super-regional shopping mall. | super-regional shopping mall =>  False\n",
      "world war i and world war ii | world war ii =>  False\n",
      "martha coolidge | martha coolidge =>  True\n",
      "mad love records | vivendi s.a. =>  False\n",
      "virginia | virginia =>  True\n",
      "10 january 1920 | 10 january 1920 =>  True\n",
      "22 november 1761 | 22 november =>  False\n",
      "1988 to 1990 | 1988 =>  False\n",
      "london | london =>  True\n",
      "dottie rambo | larnelle harris =>  False\n",
      "hawaii county | hawaii county =>  True\n",
      "\"occupied\" (2016) and \"yellow belle\" (1998). | \"now and then\" (1995) =>  False\n",
      "raffaella reggi | raffaella reggi =>  True\n",
      "john ford directed the film. | john ford =>  False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing examples:   5%|▌         | 5/100 [00:26<06:33,  4.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swoop the eagle and dooley the skeleton. | the bears =>  False\n",
      "love and theft | love and theft =>  True\n",
      "musicians and songwriters. | singer, songwriter =>  False\n",
      "1981 | 1983 =>  False\n",
      "chinese coffee | chinese coffee =>  True\n",
      "empire distribution is based in the united states. | san francisco, california =>  False\n",
      "women's interest magazines. | fortnightly women interest magazine =>  False\n",
      "the bad hemingway contest | the bad hemingway contest =>  True\n",
      "indiana university | indiana university =>  True\n",
      "seven schools. | six =>  False\n",
      "roman empire | roman =>  False\n",
      "muhammad ali fought jimmy ellis. | jimmy ellis =>  False\n",
      "matt kemp | matthew ryan kemp =>  False\n",
      "authors | novelist =>  False\n",
      "cannot determine from provided data. | matt groening =>  False\n",
      "molly hatchet. | molly hatchet =>  True\n",
      "no, only maxillaria is a genus of orchids. | no =>  False\n",
      "square enix | crystal dynamics =>  False\n",
      "steve perry | ronald shusett =>  False\n",
      "no, one is american, one is french. | no =>  False\n",
      "daredevil | daredevil =>  True\n",
      "1941 | 1941 =>  True\n",
      "yes, both are film directors. | yes =>  False\n",
      "no, they are from different countries. | no =>  False\n",
      "dubai international airport | dubai international airport =>  True\n",
      "baudot code | baudot code =>  True\n",
      "world war i | the cold war (1947–91) =>  False\n",
      "marlborough house | mark masons' hall =>  False\n",
      "kwtv-dt serves pontotoc county, oklahoma. | kxii =>  False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing examples:   6%|▌         | 6/100 [00:34<08:24,  5.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "velvetpark magazine. | velvetpark =>  False\n",
      "austrian chancellor engelbert dollfuss | a failed coup attempt =>  False\n",
      "j.r.r. tolkien | j. r. r. tolkien =>  False\n",
      "magical english nanny | fictional character =>  False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing examples:  42%|████▏     | 42/100 [00:38<00:24,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stone brewing | stone brewing =>  True\n",
      "1998 | 1998 =>  True\n",
      "grafton monster | dewey lake monster =>  False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing examples:  47%|████▋     | 47/100 [00:43<00:27,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no, they are not both based in massachusetts. | no =>  False\n",
      "novelists | author =>  False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing examples: 100%|██████████| 100/100 [01:07<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to squarepants or not to squarepants | to squarepants or not to squarepants =>  True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "score = multi_thread_executor(test_set, HotPotQASignature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score before optimization: 0.40\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average Score before optimization: {score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.teleprompt import AvatarOptimizer\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "warnings.simplefilter(\"ignore\", FutureWarning)\n",
    "\n",
    "teleprompter = AvatarOptimizer(\n",
    "    metric=metric,\n",
    "    max_iters=1,\n",
    "    max_negative_inputs=20,\n",
    "    max_positive_inputs=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\t*** In DSPy 2.5, all LM clients except `dspy.LM` are deprecated, underperform, and are about to be deleted. ***\n",
      " \t\tYou are using the client GPT3, which will be removed in DSPy 2.6.\n",
      " \t\tChanging the client is straightforward and will let you use new features (Adapters) that improve the consistency of LM outputs, especially when using chat LMs. \n",
      "\n",
      " \t\tLearn more about the changes and how to migrate at\n",
      " \t\thttps://github.com/stanfordnlp/dspy/blob/main/examples/migration.ipynb\n",
      "WARNING:root:\t*** In DSPy 2.5, all LM clients except `dspy.LM` are deprecated, underperform, and are about to be deleted. ***\n",
      " \t\tYou are using the client GPT3, which will be removed in DSPy 2.6.\n",
      " \t\tChanging the client is straightforward and will let you use new features (Adapters) that improve the consistency of LM outputs, especially when using chat LMs. \n",
      "\n",
      " \t\tLearn more about the changes and how to migrate at\n",
      " \t\thttps://github.com/stanfordnlp/dspy/blob/main/examples/migration.ipynb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Iteration 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing examples:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "belgium, europe | brussels =>  False\n",
      "jeremy paxman was born in 1950. | 1950 =>  False\n",
      "rosario dawson | rosario dawson =>  True\n",
      "kerry condon | kerry condon =>  True\n",
      "1979 | 1979 =>  True\n",
      "bruno senna | bruno senna lalli =>  False\n",
      "tae kwon do times | tae kwon do times =>  True\n",
      "the shadows | the shadows =>  True\n",
      "21 people in 2003. | 7 =>  False\n",
      "clydesdale horse | clydesdales =>  False\n",
      "douglas douglas-hamilton, 14th duke of hamilton | douglas douglas-hamilton, 14th duke of hamilton =>  True\n",
      "tea-chest bass | tea-chest bass =>  True\n",
      "jungle jim | jungle jim =>  True\n",
      "big machine records | big machine records =>  True\n",
      "james belushi, danny devito, charlie day, hugh laurie, billy bob thornton. | bill murray =>  False\n",
      "the last shadow puppets had a longer hiatus. | the last shadow puppets =>  False\n",
      "joe torre was born in 1940. | 1940 =>  False\n",
      "50 million years old. | 50-million-year-old fossil record =>  False\n",
      "space. | space =>  True\n",
      "gustavo kuerten | gustavo kuerten =>  True\n",
      "operation citadel (unternehmen zitadelle) | operation citadel =>  False\n",
      "president of the united states. | president of the united states =>  True\n",
      "bill paxton | bill paxton =>  True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing examples:   1%|          | 1/100 [00:08<14:14,  8.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2005 | 2005 =>  True\n",
      "pond hockey was created first. | pond hockey =>  False\n",
      "townes van zandt | john townes van zandt =>  False\n",
      "1882 | 1874 =>  False\n",
      "scott hayden | scott hayden =>  True\n",
      "moravian and slavic, including eastern european folk music. | moravian and other slavic folk music =>  False\n",
      "fred hoiberg | fred hoiberg =>  True\n",
      "enoch \"nucky\" johnson | enoch lewis \"nucky\" johnson =>  False\n",
      "hunting purposes. | hunting =>  False\n",
      "december 2009 for ios and maemo devices. | new zealand =>  False\n",
      "aleem dar | aleem sarwar dar =>  False\n",
      "17 january 1991 | on 17 january 1991 =>  False\n",
      "atlantic ocean | atlantic =>  False\n",
      "quatre polichinelles semblables | commedia dell'arte =>  False\n",
      "boston bruins | providence bruins =>  False\n",
      "variable oystercatcher, red-breasted dotterel, silver gull. | bryde's whales =>  False\n",
      "bryan lee vera is older. | bryan lee vera =>  False\n",
      "2010 | 2010 =>  True\n",
      "baseball, football, and basketball. | rugby =>  False\n",
      "waltz king | the waltz king =>  True\n",
      "einstein–rosen bridge (wormhole concept). | einstein =>  False\n",
      "lost | lost =>  True\n",
      "no clear evidence found.north carolina | north carolina =>  True\n",
      " | no =>  False\n",
      "no, only tiffanie debartolo is a novelist. | no =>  False\n",
      "fuller house | full house =>  False\n",
      "empire state building is taller. | the empire state building =>  False\n",
      "south africa | south africa =>  True\n",
      "davy crockett, king of the wild frontier | davy crockett, king of the wild frontier =>  True\n",
      "eastenders, created by tony holland and julia smith. | julia smith and tony holland =>  False\n",
      "only baltasar kormákur is a film producer. | no =>  False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing examples:   3%|▎         | 3/100 [00:16<08:30,  5.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "georgia | georgia =>  True\n",
      "selma lagerlöf | selma ottilia lovisa lagerlöf =>  False\n",
      "self was most recently published. | self =>  False\n",
      "aleksandr danilovich aleksandrov is older. | aleksandr danilovich aleksandrov =>  False\n",
      "asmodee was founded in 1995. | 1995 =>  False\n",
      "colorado springs airport | colorado springs municipal airport =>  False\n",
      "averroes lived longer than al-ghazali. | ibn rushd =>  False\n",
      "mixed martial artists. | mixed martial arts fighter =>  False\n",
      "margot robbie | margot elise robbie =>  False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing examples:  12%|█▏        | 12/100 [00:18<01:36,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nick at nite, hollywood heights. | nick at nite =>  False\n",
      "taste (umami flavor) | taste =>  False\n",
      "buena vista distribution | buena vista distribution =>  True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing examples:  13%|█▎        | 13/100 [00:18<01:25,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sports specialist school. | science, technology and teaching =>  False\n",
      "sidney lumet was nominated for more. | 14 of his films were nominated =>  False\n",
      "battle of milk creek, 1879. | battle of milk creek =>  False\n",
      "film directors | film director =>  False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing examples:  14%|█▍        | 14/100 [00:20<01:26,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "american | american =>  True\n",
      "boy george, lead singer of culture club. | george alan o'dowd =>  False\n",
      "skilled and exciting outfield for the dodgers. | \"outfield of dreams\" =>  False\n",
      "no movie is based on both books. | darby o'gill and the little people =>  False\n",
      "august 23, 1988 | august 23, 1988 =>  True\n",
      "no, they play different types of music. | no =>  False\n",
      "no campus city matches population 50,046. | roskilde =>  False\n",
      "no actor stars in both. | noah taylor =>  False\n",
      "the world is not enough artist released first. | madonna =>  False\n",
      "information not found in available sources. | river thames =>  False\n",
      "metal | metal =>  True\n",
      "don williams | don williams =>  True\n",
      "no known association with an alternative rock band. | push th' little daisies =>  False\n",
      "pixar animation studios | pixar animation studios =>  True\n",
      "the devil and max devlin was released first. | the devil and max devlin =>  False\n",
      "the ocean blue was formed farther east. | the ocean blue =>  False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing examples:  16%|█▌        | 16/100 [00:22<01:34,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1895 | 2010 =>  False\n",
      "screwball comedy and literary drama. | anti-mccarthyism =>  False\n",
      "joakim noah tied with tyson chandler. | tyson chandler =>  False\n",
      "general justo josé de urquiza airport (pra / saap) | aerolíneas argentinas =>  False\n",
      "approximately 22,673. | 23,674 =>  False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing examples:  43%|████▎     | 43/100 [00:27<00:17,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bringing out the dead | bringing out the dead =>  True\n",
      "iron and steel. | iron and steel =>  True\n",
      "lubbock, texas | lubbock, texas =>  True\n",
      "yes, both are prestigious. | yes =>  False\n",
      "kapilvastu, a significant buddhist site. | lumbini =>  False\n",
      "information not clearly available. | tim kennedy =>  False\n",
      "purchase cost details are not publicly available. | $250,000 =>  False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing examples:  44%|████▍     | 44/100 [00:46<01:03,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "information not found; further research needed. | 18 days =>  False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing examples: 100%|██████████| 100/100 [01:58<00:00,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "information not found. | 1996 =>  False\n",
      "Average Score: 0.32\n",
      "Positive examples: 32\n",
      "Negative examples: 68\n",
      "Sampling 20 positive examples and 20 negative examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated new instruction: New Instruction: You will be given `Tools`, which will be a list of resources to use to accomplish the `Goal`. Your task is to evaluate the nature of the user query and decide which tool or combination of tools to use, along with the input values to provide. For straightforward, well-defined questions, continue using Wiki_SEARCH and WEB_SEARCH effectively, ensuring that if one tool does not yield results, the other is utilized. For more complex or ambiguous queries, consider using WEB_SEARCH more frequently, as it may provide more current or comprehensive information. Additionally, incorporate analytical tools for queries that require comparison or synthesis of information from multiple sources.\n",
      "\n",
      "Develop a decision-making process that includes a fallback mechanism. If the initial tool does not provide satisfactory results, automatically switch to an alternative tool. Implement a system to cross-verify information from multiple sources to ensure accuracy and completeness. This approach will help in handling queries that require more than just factual retrieval, such as those needing synthesis or comparison. Ensure that you are not overly reliant on a single tool, and be prepared to use multiple tools in tandem to achieve the desired outcome.\n",
      "\n",
      "Provide training and develop guidelines for effectively using the tools and interpreting the results. This includes understanding when to use each tool, how to synthesize information from different sources, and how to perform comparative analysis when necessary. By following these enhanced instructions, you will improve your performance on negative inputs and ensure a more comprehensive and accurate response to user queries.\n",
      "Best Actor: actor.predictor = Predict(StringSignature(goal, tools, question -> action_1\n",
      "    instructions='New Instruction: You will be given `Tools`, which will be a list of resources to use to accomplish the `Goal`. Your task is to evaluate the nature of the user query and decide which tool or combination of tools to use, along with the input values to provide. For straightforward, well-defined questions, continue using Wiki_SEARCH and WEB_SEARCH effectively, ensuring that if one tool does not yield results, the other is utilized. For more complex or ambiguous queries, consider using WEB_SEARCH more frequently, as it may provide more current or comprehensive information. Additionally, incorporate analytical tools for queries that require comparison or synthesis of information from multiple sources.\\n\\nDevelop a decision-making process that includes a fallback mechanism. If the initial tool does not provide satisfactory results, automatically switch to an alternative tool. Implement a system to cross-verify information from multiple sources to ensure accuracy and completeness. This approach will help in handling queries that require more than just factual retrieval, such as those needing synthesis or comparison. Ensure that you are not overly reliant on a single tool, and be prepared to use multiple tools in tandem to achieve the desired outcome.\\n\\nProvide training and develop guidelines for effectively using the tools and interpreting the results. This includes understanding when to use each tool, how to synthesize information from different sources, and how to perform comparative analysis when necessary. By following these enhanced instructions, you will improve your performance on negative inputs and ensure a more comprehensive and accurate response to user queries.'\n",
      "    goal = Field(annotation=str required=True json_schema_extra={'prefix': 'Goal:', 'desc': 'Task to be accomplished.', '__dspy_field_type': 'input'})\n",
      "    tools = Field(annotation=list[str] required=True json_schema_extra={'prefix': 'Tools:', 'desc': 'list of tools to use', '__dspy_field_type': 'input'})\n",
      "    question = Field(annotation=str required=True json_schema_extra={'prefix': '[[Question]]: ', 'desc': 'question to ask', 'format': <function HotPotQASignature.<lambda> at 0x7f797f9387c0>, '__dspy_field_type': 'input'})\n",
      "    action_1 = Field(annotation=Action required=True json_schema_extra={'prefix': 'Action 1:', 'desc': '1st action to take.', '__dspy_field_type': 'output'})\n",
      "))\n",
      "actor_clone.predictor = Predict(StringSignature(goal, tools, question -> action_1\n",
      "    instructions='New Instruction: You will be given `Tools`, which will be a list of resources to use to accomplish the `Goal`. Your task is to evaluate the nature of the user query and decide which tool or combination of tools to use, along with the input values to provide. For straightforward, well-defined questions, continue using Wiki_SEARCH and WEB_SEARCH effectively, ensuring that if one tool does not yield results, the other is utilized. For more complex or ambiguous queries, consider using WEB_SEARCH more frequently, as it may provide more current or comprehensive information. Additionally, incorporate analytical tools for queries that require comparison or synthesis of information from multiple sources.\\n\\nDevelop a decision-making process that includes a fallback mechanism. If the initial tool does not provide satisfactory results, automatically switch to an alternative tool. Implement a system to cross-verify information from multiple sources to ensure accuracy and completeness. This approach will help in handling queries that require more than just factual retrieval, such as those needing synthesis or comparison. Ensure that you are not overly reliant on a single tool, and be prepared to use multiple tools in tandem to achieve the desired outcome.\\n\\nProvide training and develop guidelines for effectively using the tools and interpreting the results. This includes understanding when to use each tool, how to synthesize information from different sources, and how to perform comparative analysis when necessary. By following these enhanced instructions, you will improve your performance on negative inputs and ensure a more comprehensive and accurate response to user queries.'\n",
      "    goal = Field(annotation=str required=True json_schema_extra={'prefix': 'Goal:', 'desc': 'Task to be accomplished.', '__dspy_field_type': 'input'})\n",
      "    tools = Field(annotation=list[str] required=True json_schema_extra={'prefix': 'Tools:', 'desc': 'list of tools to use', '__dspy_field_type': 'input'})\n",
      "    question = Field(annotation=str required=True json_schema_extra={'prefix': '[[Question]]: ', 'desc': 'question to ask', 'format': <function HotPotQASignature.<lambda> at 0x7f797f9387c0>, '__dspy_field_type': 'input'})\n",
      "    action_1 = Field(annotation=Action required=True json_schema_extra={'prefix': 'Action 1:', 'desc': '1st action to take.', '__dspy_field_type': 'output'})\n",
      "))\n"
     ]
    }
   ],
   "source": [
    "avatar_agent = teleprompter.compile(\n",
    "    student=avatar_agent,\n",
    "    trainset=trainset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m. night shyamalan | m. night shyamalan =>  True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing examples:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no, they are not both american. | no =>  False\n",
      "march 2, 1972 | 2 march 1972 =>  False\n",
      "baltimore and ohio railroad, baltimore, maryland. | the port of baltimore west to sandy hook =>  False\n",
      "minnesota | minnesota =>  True\n",
      "no, neither is based in massachusetts. | no =>  False\n",
      "no, they are from different countries. | no =>  False\n",
      "1927 | 1927 =>  True\n",
      "1983 | 1983 =>  True\n",
      "stedelijk museum in amsterdam. | stedelijk museum amsterdam =>  False\n",
      "\"you're next\" was filmed first. | you're next =>  False\n",
      "raffaella reggi was born first. | raffaella reggi =>  False\n",
      "sarah kerrigan in \"starcraft 2\" trilogy. | sarah kerrigan =>  False\n",
      "hawaii county | hawaii county =>  True\n",
      "marktown | marktown =>  True\n",
      "creature comforts | creature comforts =>  True\n",
      "oneida limited | oneida limited =>  True\n",
      "shakespeare's works are highly influential and widely performed. | chronological collection of critical quotations =>  False\n",
      "london | london =>  True\n",
      "super-regional shopping mall in nashville, tennessee. | super-regional shopping mall =>  False\n",
      "arthur p. jacobs | ronald shusett =>  False\n",
      "martha coolidge | martha coolidge =>  True\n",
      "dorothea jordan, born 21 november 1761. | 22 november =>  False\n",
      "cannes film festival 2016. | 69th cannes film festival =>  False\n",
      "benny | lester =>  False\n",
      "romeo montague slays tybalt, not benvolio. | tybalt =>  False\n",
      "crystal dynamics | crystal dynamics =>  True\n",
      "john ford directed the film. | john ford =>  False\n",
      "roman empire | roman =>  False\n",
      "adam levine | adam levine =>  True\n",
      "professor dame angela mclean | frederick alexander =>  False\n",
      "bhaktivedanta manor | in the village of aldenham =>  False\n",
      "the dark tower by stephen king. | the dark tower =>  False\n",
      "1978 | 1978 =>  True\n",
      "love and theft | love and theft =>  True\n",
      "magical english nanny mary poppins. | fictional character =>  False\n",
      "world war i and world war ii. | world war ii =>  False\n",
      "discovery zone was founded in missouri. | discovery zone =>  False\n",
      "blue grass airport, lexington, kentucky. | blue grass airport =>  False\n",
      "enigma recorded the song \"amen\" with aquilo. | enigma =>  False\n",
      "chukchansi park | sam boyd stadium =>  False\n",
      "indiana university | indiana university =>  True\n",
      "albany, new york. | new york =>  False\n",
      "lancaster, pennsylvania | bath, maine =>  False\n",
      "costa mesa, california. | california =>  False\n",
      "not a european city. | lacoste, france =>  False\n",
      "ricky rubio | ricard rubio i vives =>  False\n",
      "velvetpark is more for a lesbian readership. | velvetpark =>  False\n",
      "colors and blocks in baudot code. | baudot code =>  False\n",
      "woman's era: women's interest; naj: jewelry industry. | fortnightly women interest magazine =>  False\n",
      "\"shukratara\", \"ya janmavar\", \"swargangechya kathavarti\". | shukratara =>  False\n",
      "\"another stakeout\" (1993) | \"now and then\" (1995) =>  False\n",
      "chinese coffee | chinese coffee =>  True\n",
      "papa gino's headquarters is further north. | papa gino's =>  False\n",
      "musician, singer, songwriter. | singer, songwriter =>  False\n",
      "stone brewing. | stone brewing =>  True\n",
      "rené artois | captain hans geering =>  False\n",
      "molly hatchet | molly hatchet =>  True\n",
      "dubai international airport, terminal 2 | dubai international airport =>  False\n",
      "aloe vera of america | aloe vera of america =>  True\n",
      "sandi patty | larnelle harris =>  False\n",
      "no assassination linked to rome protocols. | a failed coup attempt =>  False\n",
      "james loney | matthew ryan kemp =>  False\n",
      "lord dooley, a skeleton. | the bears =>  False\n",
      "the twist. | the twist =>  True\n",
      "1988 to 1990 | 1988 =>  False\n",
      "daredevil | daredevil =>  True\n",
      "loughborough university | loughborough university =>  True\n",
      "\"to squarepants or not to squarepants\" aired first. | to squarepants or not to squarepants =>  False\n",
      "new york and new jersey campaign. | new york and new jersey campaign =>  True\n",
      "\"read it and weep\" | \"read it and weep\" (2006) =>  False\n",
      "universal music group | vivendi s.a. =>  False\n",
      "marlborough house | mark masons' hall =>  False\n",
      "no such contest in california exists. | the bad hemingway contest =>  False\n",
      "teen titans go! | teen titans go! =>  True\n",
      "seven schools. | six =>  False\n",
      "mothman. | dewey lake monster =>  False\n",
      "novelists | author =>  False\n",
      "10 january 1920 | 10 january 1920 =>  True\n",
      "1941 | 1941 =>  True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing examples:   1%|          | 1/100 [00:19<32:59, 19.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only maxillaria is a genus of orchids. | no =>  False\n",
      "anne perry | anne perry =>  True\n",
      "2011 pulitzer prize in general nonfiction finalist. | pulitzer prize =>  False\n",
      "viva is not an acronym. | gesellschaft mit beschränkter haftung =>  False\n",
      "german culture | german =>  False\n",
      "jonny craig has been in more bands. | jonny\" craig =>  False\n",
      "san francisco | san francisco, california =>  False\n",
      "no common services identified. | cleaning, catering and security =>  False\n",
      "virginia | virginia =>  True\n",
      "world war i. | the cold war (1947–91) =>  False\n",
      "1998 | 1998 =>  True\n",
      "yes, both are film directors. | yes =>  False\n",
      "kxii serves pontotoc county, oklahoma. | kxii =>  False\n",
      "matthew abraham groening | matt groening =>  False\n",
      "j. r. r. tolkien | j. r. r. tolkien =>  True\n",
      "both are novelists. | novelist =>  False\n",
      "oklahoma sooners | oklahoma sooners =>  True\n",
      "no documented fight in houston after frazier. | jimmy ellis =>  False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing examples:   7%|▋         | 7/100 [00:45<09:06,  5.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creed disbanded in june 2004. | 2004 =>  False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing examples: 100%|██████████| 100/100 [00:47<00:00,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "supply chain management | engineering =>  False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "score = multi_thread_executor(test_set, HotPotQASignature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can evaluate our actor module, for this we've provided an implementation of thread safe evaluator that we above as part of class method of `AvatarOptimizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score: 0.31\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average Score: {score:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stark11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
